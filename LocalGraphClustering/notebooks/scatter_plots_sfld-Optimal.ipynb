{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "\n",
    "data_path = os.getcwd()\n",
    "\n",
    "try:\n",
    "    import localgraphclustering as lgc\n",
    "except:\n",
    "    # when the package is not installed, import the local version instead. \n",
    "    # the notebook must be placed in the original \"notebooks/\" folder\n",
    "    sys.path.append(\"../\")\n",
    "    import localgraphclustering as lgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the graph_tool module for visualization.\n",
    "from graph_tool.all import * \n",
    "\n",
    "import statistics as stat_\n",
    "\n",
    "# The following code is for random generation of colors.\n",
    "# See here: https://stackoverflow.com/questions/14720331/how-to-generate-random-colors-in-matplotlib\n",
    "def rand_cmap(nlabels, type='bright', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "\n",
    "    np.random.seed(seed=10)\n",
    "    np.random.RandomState(seed=10)\n",
    "\n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in range(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in range(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/localgraphclustering/GraphLocal.py:217: UserWarning:\n",
      "\n",
      "Loading a graphml is not efficient, we suggest using an edgelist format for this API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read graph. This also supports gml format.\n",
    "#g = lgc.GraphLocal(os.path.join(data_path,'datasets/JohnsHopkins.graphml'),'graphml')\n",
    "g = lgc.GraphLocal('./datasets/sfld_brown_et_al_amidohydrolases_protein_similarities_for_beh.graphml','graphml',' ')\n",
    "# To get a quick look at the list of methods and attributes for the graph object 'g' you can type 'g.' + tab\n",
    "# and scroll up or down.\n",
    "\n",
    "vol_G = g.vol_G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph using GraphTool. We do this to handle some meta-data which LocalGraphClustering is not handling yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_gtool = load_graph('datasets/sfld_brown_et_al_amidohydrolases_protein_similarities_for_beh.graphml')\n",
    "remove_self_loops(g_gtool)\n",
    "\n",
    "n = g_gtool.num_vertices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load coordinates for graph layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed coordinates for nodes.\n",
    "ld_coord = np.loadtxt('./datasets/sfld_brown_et_al_amidohydrolases_protein_similarities_for_beh_coordinates.xy', dtype = 'str')\n",
    "\n",
    "temp = []\n",
    "for i in ld_coord:\n",
    "    temp.append(i[0])\n",
    "\n",
    "idxs = dict(zip(temp, range(len(temp)))) \n",
    "\n",
    "pos = g_gtool.new_vertex_property(\"vector<double>\")\n",
    "for i in ld_coord:\n",
    "    pos[idxs[i[0]]] = i[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and filter ground truth clusters. This part takes a while to run. The results are saved in results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached\n",
      "Number of feature 0 Feature value  22.0  gap  [0.91796738]  volume:  16209.0  size: 100 conductance:  0.42254370102471367\n"
     ]
    }
   ],
   "source": [
    "g_v_prop = g_gtool.vertex_properties\n",
    "groups = np.loadtxt('./datasets/sfld_brown_et_al_amidohydrolases_protein_similarities_for_beh.class', dtype = 'float')\n",
    "feature_list = [groups]\n",
    "\n",
    "number_feature = 0\n",
    "\n",
    "ref_nodes = []\n",
    "info_ref_nodes = []\n",
    "\n",
    "for kk in feature_list:\n",
    "    \n",
    "    feature = kk\n",
    "\n",
    "    for ff in list(set(feature)):\n",
    "        \n",
    "        if ff == 0:\n",
    "            continue\n",
    "\n",
    "        feature_array = np.zeros(n)\n",
    "        feature_ff_nodes = []\n",
    "        for i in range(n):\n",
    "            feature_array[i] = feature[i]\n",
    "            if feature_array[i] == ff:\n",
    "                feature_ff_nodes.append(i)\n",
    "\n",
    "        g_ff = g_gtool.copy()\n",
    "\n",
    "        del_list_ff = list(set(range(n)) - set(feature_ff_nodes))\n",
    "\n",
    "        for v in reversed(sorted(del_list_ff)):\n",
    "            g_ff.remove_vertex(v)   \n",
    "\n",
    "        n_ff = g_ff.num_vertices() \n",
    "\n",
    "        comp_ff,hist_ff=label_components(g_ff)\n",
    "\n",
    "        feature_ff_nodes_largest_component = []\n",
    "        for i in range(n_ff):\n",
    "            if comp_ff[i] == 0:\n",
    "                feature_ff_nodes_largest_component.append(feature_ff_nodes[i])    \n",
    "\n",
    "        vol_ff = sum(g.d[feature_ff_nodes_largest_component])\n",
    "        \n",
    "        if vol_ff < 100:\n",
    "            continue\n",
    "            \n",
    "        #temp = np.zeros(n)\n",
    "        #temp[feature_ff_nodes_largest_component] = 1\n",
    "        \n",
    "        #cut_ff = vol_ff - (g.adjacency_matrix.dot(temp).transpose()).dot(temp)\n",
    "        #cond_ff = cut_ff/min(vol_ff,vol_G - vol_ff)\n",
    "        cond_ff = g.compute_conductance(feature_ff_nodes_largest_component,cpp=True)\n",
    "        \n",
    "        if cond_ff > 0.47:\n",
    "            continue\n",
    "            \n",
    "        print(\"Reached\")\n",
    "        eig_ff, lambda_ff = lgc.fiedler_local(g, feature_ff_nodes_largest_component)\n",
    "        lambda_ff = np.real(lambda_ff)\n",
    "        gap_ff = lambda_ff/cond_ff\n",
    "        \n",
    "        print(\"Number of feature\", number_feature, \"Feature value \", ff, \" gap \",gap_ff, \" volume: \", vol_ff, \" size:\", len(feature_ff_nodes_largest_component), \"conductance: \", cond_ff)\n",
    "        \n",
    "        if gap_ff >= 0.5 and vol_ff >= 100:\n",
    "            ref_nodes.append(feature_ff_nodes_largest_component)\n",
    "            info_ref_nodes.append([number_feature,ff])\n",
    "            np.save('results/ref_nodes_sfld', ref_nodes) \n",
    "            np.save('results/info_ref_nodes_sfld', info_ref_nodes) \n",
    "        \n",
    "    number_feature += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have generated the ground truth datasets once, you can avoid rerunning the above code and simple run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_nodes = np.load('results/ref_nodes_sfld.npy') \n",
    "info_ref_nodes = np.load('results/info_ref_nodes_sfld.npy') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the ground truth clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PropertyMap object with key type 'Vertex' and value type 'vector<double>', for Graph 0x13cc85438, at 0x13cc72da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.zeros(n)\n",
    "temp = temp + 3\n",
    "\n",
    "temp2 = np.zeros(n, dtype=int)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in ref_nodes:\n",
    "    \n",
    "    temp[i] = 6\n",
    "    \n",
    "    for j in i:\n",
    "        temp2[j] = int(info_ref_nodes[counter,1])\n",
    "    counter += 1\n",
    "\n",
    "node_size = g_gtool.new_vertex_property(\"double\",temp)\n",
    "\n",
    "node_colours = g_gtool.new_vertex_property(\"vector<double>\")\n",
    "\n",
    "c_map = rand_cmap(n, type='bright', first_color_black=False, last_color_black=False, verbose=False)\n",
    "\n",
    "for i in range(n):\n",
    "    node_colours[i] = [0,0,0]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in ref_nodes:\n",
    "    \n",
    "    for j in i:\n",
    "        node_colours[j] = c_map(int(info_ref_nodes[counter,1]))\n",
    "    counter += 1\n",
    "\n",
    "#def get_cmap(n, name='hsv'):\n",
    "#    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "#    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "#    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "#c_map = get_cmap(g_gtool.num_vertices())\n",
    "\n",
    "#c_map = rand_cmap(n, type='bright', first_color_black=True, last_color_black=False, verbose=True)\n",
    "\n",
    "graph_draw(g_gtool, pos, output_size=(1000, 500),\n",
    "           vertex_size=node_size, \n",
    "           vertex_fill_color=node_colours, \n",
    "           vorder=node_size,\n",
    "           edge_pen_width=1,\n",
    "           edge_color = [0.0, 0, 0, 0.05],\n",
    "           #vcmap = c_map\n",
    "           output='sfld_selected.png'\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results by spectral algorithm: https://dl.acm.org/citation.cfm?id=1170528 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.4126234435379991 f1score:  0.8243996097069655 precision:  0.8415370774964658 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4398547435315479 f1score:  0.718070260931201 precision:  0.5601479075232402 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.4683935820606998 f1score:  0.7535300050428644 precision:  0.770281590308654 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.45757243337420145 f1score:  0.780924274770815 precision:  0.795052099980822 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4411492122335496 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.438578352180937 f1score:  0.8750078433833218 precision:  0.8902010852218321 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.4288659793814433 f1score:  0.8897223360332819 precision:  0.9094716494845361 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.43260953359886933 f1score:  0.8454834345404776 precision:  0.8627199178117375 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7726027397260274 precision:  0.7890775762253956 recall:  0.7568017767906718\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.43097913322632425 f1score:  0.7520171457387796 precision:  0.7687350989110123 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.453130026378434 f1score:  0.7825567502986858 precision:  0.7979098544591908 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.4305421259588732 f1score:  0.8577643275959902 precision:  0.8770063817443434 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.4293244198752973 f1score:  0.8666960241570206 precision:  0.8841044728229481 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4411492122335496 f1score:  0.7206974694699735 precision:  0.7356550793548802 recall:  0.706335986180517\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4472497745716862 f1score:  0.7616528092718569 precision:  0.7779707907096443 recall:  0.7460053056943673\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.4810224632068164 f1score:  0.7494114323382617 precision:  0.7628450920245399 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.45757243337420145 f1score:  0.780924274770815 precision:  0.795052099980822 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.45503701319600903 f1score:  0.7919783743006223 precision:  0.8073053508490868 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.4339890357949049 f1score:  0.8652179374450445 precision:  0.8811000959385993 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.44205511202678344 f1score:  0.8466651964336347 precision:  0.8651171774401236 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.4688465499485067 f1score:  0.7407034859962908 precision:  0.7550628044091259 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.42621599340478156 f1score:  0.7520882584712372 precision:  0.7688837329208559 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4256546826453617 f1score:  0.8256990637117366 precision:  0.8442496132026818 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4856885572779314 f1score:  0.7212495276483185 precision:  0.7366051328230527 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.45236405856930917 f1score:  0.8016451086274017 precision:  0.816147797737007 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4220264317180617 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7285063609235118 precision:  0.7420965058236273 recall:  0.7154050219014128\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4411492122335496 f1score:  0.7426537746842619 precision:  0.758589628104491 recall:  0.7273736812881733\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.45503701319600903 f1score:  0.7919783743006223 precision:  0.8073053508490868 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4126234435379991 f1score:  0.8336318220378924 precision:  0.8494045332308875 recall:  0.8184342032204331\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.4305421259588732 f1score:  0.8577643275959902 precision:  0.8770063817443434 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.42488888888888887 f1score:  0.7918513628218429 precision:  0.8073076923076923 recall:  0.7769757542106237\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.41677531508039983 f1score:  0.7393806005345072 precision:  0.7539112592972557 recall:  0.7253994694305632\n",
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4624236579877853 f1score:  0.7735171892708728 precision:  0.789778206364513 recall:  0.7579122709605774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.49607515120319134 f1score:  0.6596957576139334 precision:  0.6738514991635568 recall:  0.6461225245234129\n",
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.46748308088946183 f1score:  0.7308538041088144 precision:  0.744512 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4220264317180617 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4209104938271605 f1score:  0.8886999779603917 precision:  0.90747170781893 recall:  0.870689123326547\n"
     ]
    }
   ],
   "source": [
    "nodes = {}\n",
    "external_best_cond_acl = {}\n",
    "external_best_pre_cond_acl = {}\n",
    "gap_best_cond_acl = {}\n",
    "gap_best_pre_acl = {}\n",
    "vol_best_cond_acl = {}\n",
    "vol_best_pre_acl = {}\n",
    "size_clust_best_cond_acl = {}\n",
    "size_clust_best_pre_acl = {}\n",
    "f1score_best_cond_acl = {}\n",
    "f1score_best_pre_acl = {}\n",
    "true_positives_best_cond_acl = {}\n",
    "true_positives_best_pre_acl = {}\n",
    "precision_best_cond_acl = {}\n",
    "precision_best_pre_acl = {}\n",
    "recall_best_cond_acl = {}\n",
    "recall_best_pre_acl = {}\n",
    "cuts_best_cond_acl = {}\n",
    "cuts_best_pre_acl = {}\n",
    "cuts_acl_ALL = {}\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "    \n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)\n",
    "    \n",
    "    nodes[ct_outer] = np.random.choice(rr, how_many, replace=False)\n",
    "    \n",
    "    eigv, lambda_val = lgc.fiedler_local(g, rr)\n",
    "    lambda_val = np.real(lambda_val)\n",
    "    \n",
    "    step = (2*lambda_val - lambda_val/2)/4\n",
    "    \n",
    "    a_list = np.arange(lambda_val/2,2*lambda_val,step)\n",
    "\n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        max_precision = -1\n",
    "        min_conduct = 100\n",
    "        \n",
    "        ct_inner = 0\n",
    "        for a in a_list:\n",
    "\n",
    "            rho = 0.2/sum(g.d[rr])\n",
    "            \n",
    "            output_pr_clustering = lgc.spectral_clustering(g,ref_node,method=\"l1reg\",alpha=a,rho=rho,epsilon=1.0e-2,iterations=1000)\n",
    "            \n",
    "            S_l1pr = output_pr_clustering[0]\n",
    "            \n",
    "            cuts_acl_ALL[ct_outer,node,ct_inner] = S_l1pr\n",
    "            \n",
    "            size_clust_acl_ = len(S_l1pr)\n",
    "            \n",
    "            cond_val_l1pr = output_pr_clustering[1]\n",
    "            \n",
    "            vol_ = sum(g.d[S_l1pr])\n",
    "            true_positives_acl_ = set(rr).intersection(S_l1pr)\n",
    "            if len(true_positives_acl_) == 0:\n",
    "                true_positives_acl_ = set(ref_node)\n",
    "                vol_ = g.d[ref_node][0,0]\n",
    "            precision = sum(g.d[np.array(list(true_positives_acl_))])/vol_\n",
    "            recall = sum(g.d[np.array(list(true_positives_acl_))])/sum(g.d[rr])\n",
    "            f1_score_ = 2*(precision*recall)/(precision + recall)\n",
    "            \n",
    "            if f1_score_ >= max_precision:\n",
    "            \n",
    "                max_precision = f1_score_\n",
    "            \n",
    "                if len(S_l1pr) == 1:\n",
    "                    S_smqi_val = 1\n",
    "                else:\n",
    "                    S_smqi, S_smqi_val = lgc.fiedler_local(g, S_l1pr)\n",
    "                    S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "                external_best_pre_cond_acl[ct_outer,node] = cond_val_l1pr\n",
    "                gap_best_pre_acl[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_l1pr])))/cond_val_l1pr\n",
    "                vol_best_pre_acl[ct_outer,node] = vol_\n",
    "\n",
    "                size_clust_best_pre_acl[ct_outer,node] = size_clust_acl_\n",
    "                true_positives_best_pre_acl[ct_outer,node] = true_positives_acl_\n",
    "                precision_best_pre_acl[ct_outer,node] = precision\n",
    "                recall_best_pre_acl[ct_outer,node] = recall\n",
    "                f1score_best_pre_acl[ct_outer,node] = f1_score_\n",
    "                \n",
    "                cuts_best_pre_acl[ct_outer,node] = S_l1pr\n",
    "                \n",
    "            if cond_val_l1pr <= min_conduct:\n",
    "            \n",
    "                min_conduct = cond_val_l1pr\n",
    "            \n",
    "                if len(S_l1pr) == 1:\n",
    "                    S_smqi_val = 1\n",
    "                else:\n",
    "                    S_smqi, S_smqi_val = lgc.fiedler_local(g, S_l1pr)\n",
    "                    S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "                external_best_cond_acl[ct_outer,node] = cond_val_l1pr\n",
    "                gap_best_cond_acl[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_l1pr])))/cond_val_l1pr\n",
    "                vol_best_cond_acl[ct_outer,node] = vol_\n",
    "\n",
    "                size_clust_best_cond_acl[ct_outer,node] = size_clust_acl_\n",
    "                true_positives_best_cond_acl[ct_outer,node] = true_positives_acl_\n",
    "                precision_best_cond_acl[ct_outer,node] = precision\n",
    "                recall_best_cond_acl[ct_outer,node] = recall\n",
    "                f1score_best_cond_acl[ct_outer,node] = f1_score_\n",
    "                \n",
    "                cuts_best_cond_acl[ct_outer,node] = S_l1pr\n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', external_best_cond_acl[ct_outer,node], 'f1score: ', f1score_best_pre_acl[ct_outer,node], 'precision: ', precision_best_pre_acl[ct_outer,node], 'recall: ', recall_best_pre_acl[ct_outer,node])\n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "    \n",
    "    np.save('results/size_clust_best_cond_acl_sfld', size_clust_best_cond_acl) \n",
    "    np.save('results/external_best_cond_acl_sfld', external_best_cond_acl)\n",
    "    np.save('results/vol_best_cond_acl_sfld', vol_best_cond_acl) \n",
    "    np.save('results/gap_best_cond_acl_sfld', gap_best_cond_acl) \n",
    "    np.save('results/cuts_best_cond_acl_sfld', cuts_best_cond_acl) \n",
    "    np.save('results/true_positives_best_cond_acl_sfld', true_positives_best_cond_acl)\n",
    "    np.save('results/f1score_best_cond_acl_sfld', f1score_best_cond_acl) \n",
    "    np.save('results/precision_best_cond_acl_sfld', precision_best_cond_acl) \n",
    "    np.save('results/recall_best_cond_acl_sfld', recall_best_cond_acl) \n",
    "\n",
    "    np.save('results/size_clust_best_pre_acl_sfld', size_clust_best_pre_acl) \n",
    "    np.save('results/external_best_pre_cond_acl_sfld', external_best_pre_cond_acl)\n",
    "    np.save('results/vol_best_pre_acl_sfld', vol_best_pre_acl) \n",
    "    np.save('results/gap_best_pre_acl_sfld', gap_best_pre_acl) \n",
    "    np.save('results/cuts_best_pre_acl_sfld', cuts_best_pre_acl) \n",
    "    np.save('results/true_positives_best_pre_acl_sfld', true_positives_best_pre_acl)\n",
    "    np.save('results/f1score_best_pre_acl_sfld', f1score_best_pre_acl) \n",
    "    np.save('results/precision_best_pre_acl_sfld', precision_best_pre_acl) \n",
    "    np.save('results/recall_best_pre_acl_sfld', recall_best_pre_acl) \n",
    "\n",
    "    np.save('results/cuts_acl_ALL_sfld', cuts_acl_ALL) \n",
    "    \n",
    "    np.save('results/nodes_sfld', nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the results found by the spectral algorithm using MQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.438118493766868 f1score:  0.8243996097069655 precision:  0.8415370774964658 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.46773250146227335 f1score:  0.7566780605139891 precision:  0.7768895821147722 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4512658635573021 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.43108580302834215 f1score:  0.8808388339702493 precision:  0.9023553772486088 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.42756368386675375 f1score:  0.8956502427107458 precision:  0.9219464402351404 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.431287589730324 f1score:  0.8484465774185401 precision:  0.868912888831404 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.46314164415283676 f1score:  0.7726027397260274 precision:  0.7890775762253956 recall:  0.7568017767906718\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.462465365036407 f1score:  0.7520171457387796 precision:  0.7687350989110123 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.44976076555023925 f1score:  0.7857932123125494 precision:  0.8046683046683046 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.42748190279214066 f1score:  0.8697326473280516 precision:  0.8904472595656671 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4702820792906252 f1score:  0.7206974694699735 precision:  0.7356550793548802 recall:  0.706335986180517\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4586573354069466 f1score:  0.7643247684965709 precision:  0.7835666148263349 recall:  0.7460053056943673\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.46871008939974457 f1score:  0.767998455896545 precision:  0.8023795119983868 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.42921696468917436 f1score:  0.8691482649842271 precision:  0.8892905558065973 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.4361547603327611 f1score:  0.8570881837027586 precision:  0.8871649280338043 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.46589072098286455 f1score:  0.7439540316979226 precision:  0.7618493372130618 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.46004124774426397 f1score:  0.7520882584712372 precision:  0.7688837329208559 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4453226224410469 f1score:  0.8276820982777691 precision:  0.8484063228815756 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4823670852257547 f1score:  0.734549886148616 precision:  0.7648944696767299 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.44709765094156473 f1score:  0.8064556882066831 precision:  0.8261826182618262 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4724764728632203 f1score:  0.7285063609235118 precision:  0.7420965058236273 recall:  0.7154050219014128\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4677647664393257 f1score:  0.7426537746842619 precision:  0.758589628104491 recall:  0.7273736812881733\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4351243396469527 f1score:  0.8336318220378924 precision:  0.8494045332308875 recall:  0.8184342032204331\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.4511951549513562 f1score:  0.7938228805546802 precision:  0.8114167901552735 recall:  0.7769757542106237\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.4643592382913021 f1score:  0.7393806005345072 precision:  0.7539112592972557 recall:  0.7253994694305632\n",
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4617280747275558 f1score:  0.7769169960474309 precision:  0.7968993253762325 recall:  0.7579122709605774\n",
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.4951970851275257 f1score:  0.6691157679529771 precision:  0.6938058959920503 recall:  0.6461225245234129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.4640969446951141 f1score:  0.7334110897456104 precision:  0.7498388552275365 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4209104938271605 f1score:  0.8886999779603917 precision:  0.90747170781893 recall:  0.870689123326547\n"
     ]
    }
   ],
   "source": [
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_cond_acl_flow = {}\n",
    "gap_acl_flow = {}\n",
    "vol_acl_flow = {}\n",
    "size_clust_acl_flow = {}\n",
    "f1score_acl_flow = {}\n",
    "true_positives_acl_flow = {}\n",
    "precision_acl_flow = {}\n",
    "recall_acl_flow = {}\n",
    "cuts_acl_flow = {}\n",
    "\n",
    "cuts_best_pre_acl = np.load('results/cuts_best_pre_acl_sfld.npy')\n",
    "cuts_best_pre_acl = cuts_best_pre_acl[()]\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "    \n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)\n",
    "\n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        ref_set = cuts_best_pre_acl[ct_outer,node]\n",
    "\n",
    "        output_mqi = lgc.flow_clustering(g,ref_set,method=\"mqi\")\n",
    "        \n",
    "        S_flowI = output_mqi[0]\n",
    "        \n",
    "        cuts_acl_flow[ct_outer,node] = S_flowI\n",
    "\n",
    "        S_smqi, S_smqi_val = lgc.fiedler_local(g, S_flowI)\n",
    "        S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "        cond_val_acl_flow = output_mqi[1]\n",
    "\n",
    "        external_cond_acl_flow[ct_outer,node] = cond_val_acl_flow\n",
    "        gap_acl_flow[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_flowI])))/cond_val_acl_flow\n",
    "        vol_acl_flow[ct_outer,node] = sum(g.d[S_flowI])\n",
    "        size_clust_acl_flow[ct_outer,node] = len(S_flowI)\n",
    "            \n",
    "        true_positives_acl_flow[ct_outer,node] = set(rr).intersection(S_flowI)\n",
    "        if len(true_positives_acl_flow[ct_outer,node]) == 0:\n",
    "            true_positives_acl_flow[ct_outer,node] = set(ref_node)\n",
    "            vol_acl_flow[ct_outer,node] = g.d[ref_node][0]\n",
    "        precision_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/vol_acl_flow[ct_outer,node]\n",
    "        recall_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/sum(g.d[rr])\n",
    "        f1score_acl_flow[ct_outer,node] = 2*(precision_acl_flow[ct_outer,node]*recall_acl_flow[ct_outer,node])/(precision_acl_flow[ct_outer,node] + recall_acl_flow[ct_outer,node])\n",
    "            \n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', cond_val_acl_flow, 'f1score: ', f1score_acl_flow[ct_outer,node], 'precision: ', precision_acl_flow[ct_outer,node], 'recall: ', recall_acl_flow[ct_outer,node])\n",
    "        \n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "\n",
    "    np.save('results/size_clust_best_acl_flow_mqi_sfld', size_clust_acl_flow) \n",
    "    np.save('results/external_cond_best_acl_flow_mqi_sfld', external_cond_acl_flow)\n",
    "    np.save('results/vol_best_acl_flow_mqi_sfld', vol_acl_flow) \n",
    "    np.save('results/gap_best_acl_flow_mqi_sfld', gap_acl_flow) \n",
    "    np.save('results/cuts_best_acl_flow_mqi_sfld', cuts_acl_flow) \n",
    "    np.save('results/true_positives_best_acl_flow_mqi_sfld', true_positives_acl_flow)\n",
    "    np.save('results/recall_best_acl_flow_mqi_sfld', recall_acl_flow) \n",
    "    np.save('results/precision_best_acl_flow_mqi_sfld', precision_acl_flow) \n",
    "    np.save('results/f1score_best_acl_flow_mqi_sfld', f1score_acl_flow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the results found by the spectral algorithm using FlowImprove (SimpleLocal with delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4398547435315479 f1score:  0.718070260931201 precision:  0.5601479075232402 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.46773250146227335 f1score:  0.7566780605139891 precision:  0.7768895821147722 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4512658635573021 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.43108580302834215 f1score:  0.8808388339702493 precision:  0.9023553772486088 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.42756368386675375 f1score:  0.8956502427107458 precision:  0.9219464402351404 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.431287589730324 f1score:  0.8484465774185401 precision:  0.868912888831404 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.44976076555023925 f1score:  0.7857932123125494 precision:  0.8046683046683046 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.42488888888888887 f1score:  0.7188185990820195 precision:  0.5610591900311527 recall:  1.0\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.42748190279214066 f1score:  0.8697326473280516 precision:  0.8904472595656671 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4411492122335496 f1score:  0.7173552255980173 precision:  0.5592781726588917 recall:  1.0\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4472497745716862 f1score:  0.7183089229132968 precision:  0.5604384205794897 recall:  1.0\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.46871008939974457 f1score:  0.767998455896545 precision:  0.8023795119983868 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.42921696468917436 f1score:  0.8691482649842271 precision:  0.8892905558065973 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.4361547603327611 f1score:  0.8570881837027586 precision:  0.8871649280338043 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.46589072098286455 f1score:  0.7439540316979226 precision:  0.7618493372130618 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4256546826453617 f1score:  0.7188664183076104 precision:  0.5611174576799253 recall:  1.0\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4823670852257547 f1score:  0.734549886148616 precision:  0.7648944696767299 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.44709765094156473 f1score:  0.8064556882066831 precision:  0.8261826182618262 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4411492122335496 f1score:  0.7173552255980173 precision:  0.5592781726588917 recall:  1.0\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.42488888888888887 f1score:  0.7188185990820195 precision:  0.5610591900311527 recall:  1.0\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.42488888888888887 f1score:  0.7188185990820195 precision:  0.5610591900311527 recall:  1.0\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n",
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4617280747275558 f1score:  0.7769169960474309 precision:  0.7968993253762325 recall:  0.7579122709605774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.4951970851275257 f1score:  0.6691157679529771 precision:  0.6938058959920503 recall:  0.6461225245234129\n",
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.45996658527181594 f1score:  0.7319344386069776 precision:  0.7467582488124278 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4126234435379991 f1score:  0.7200799644602399 precision:  0.5625976189649786 recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_cond_acl_flow = {}\n",
    "gap_acl_flow = {}\n",
    "vol_acl_flow = {}\n",
    "size_clust_acl_flow = {}\n",
    "f1score_acl_flow = {}\n",
    "true_positives_acl_flow = {}\n",
    "precision_acl_flow = {}\n",
    "recall_acl_flow = {}\n",
    "cuts_acl_flow = {}\n",
    "\n",
    "cuts_best_pre_acl = np.load('results/cuts_best_pre_acl_sfld.npy')\n",
    "cuts_best_pre_acl = cuts_best_pre_acl[()]\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "    \n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)\n",
    "\n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        ref_set = cuts_best_pre_acl[ct_outer,node]\n",
    "\n",
    "        output_mqi = lgc.flow_clustering(g,ref_set,method=\"sl\",delta=0.00000000001)\n",
    "        \n",
    "        S_flowI = output_mqi[0]\n",
    "        \n",
    "        cuts_acl_flow[ct_outer,node] = S_flowI\n",
    "\n",
    "        S_smqi, S_smqi_val = lgc.fiedler_local(g, S_flowI)\n",
    "        S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "        cond_val_acl_flow = output_mqi[1]\n",
    "\n",
    "        external_cond_acl_flow[ct_outer,node] = cond_val_acl_flow\n",
    "        gap_acl_flow[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_flowI])))/cond_val_acl_flow\n",
    "        vol_acl_flow[ct_outer,node] = sum(g.d[S_flowI])\n",
    "        size_clust_acl_flow[ct_outer,node] = len(S_flowI)\n",
    "            \n",
    "        true_positives_acl_flow[ct_outer,node] = set(rr).intersection(S_flowI)\n",
    "        if len(true_positives_acl_flow[ct_outer,node]) == 0:\n",
    "            true_positives_acl_flow[ct_outer,node] = set(ref_node)\n",
    "            vol_acl_flow[ct_outer,node] = g.d[ref_node][0]\n",
    "        precision_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/vol_acl_flow[ct_outer,node]\n",
    "        recall_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/sum(g.d[rr])\n",
    "        f1score_acl_flow[ct_outer,node] = 2*(precision_acl_flow[ct_outer,node]*recall_acl_flow[ct_outer,node])/(precision_acl_flow[ct_outer,node] + recall_acl_flow[ct_outer,node])\n",
    "            \n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', cond_val_acl_flow, 'f1score: ', f1score_acl_flow[ct_outer,node], 'precision: ', precision_acl_flow[ct_outer,node], 'recall: ', recall_acl_flow[ct_outer,node])\n",
    "        \n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "\n",
    "    np.save('results/size_clust_best_acl_flow_flowImprove_sfld', size_clust_acl_flow) \n",
    "    np.save('results/external_cond_best_acl_flow_flowImprove_sfld', external_cond_acl_flow)\n",
    "    np.save('results/vol_best_acl_flow_flowImprove_sfld', vol_acl_flow) \n",
    "    np.save('results/gap_best_acl_flow_flowImprove_sfld', gap_acl_flow) \n",
    "    np.save('results/cuts_best_acl_flow_flowImprove_sfld', cuts_acl_flow) \n",
    "    np.save('results/true_positives_best_acl_flow_flowImprove_sfld', true_positives_acl_flow)\n",
    "    np.save('results/recall_best_acl_flow_flowImprove_sfld', recall_acl_flow) \n",
    "    np.save('results/precision_best_acl_flow_flowImprove_sfld', precision_acl_flow) \n",
    "    np.save('results/f1score_best_acl_flow_flowImprove_sfld', f1score_acl_flow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the results found by the spectral algorithm using Local FlowImprove (or SimpleLocal since they solve the same optimization problem using a different solver for the subproblem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.438118493766868 f1score:  0.8243996097069655 precision:  0.8415370774964658 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4398547435315479 f1score:  0.718070260931201 precision:  0.5601479075232402 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.46773250146227335 f1score:  0.7566780605139891 precision:  0.7768895821147722 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4512658635573021 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.43108580302834215 f1score:  0.8808388339702493 precision:  0.9023553772486088 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.42756368386675375 f1score:  0.8956502427107458 precision:  0.9219464402351404 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.431287589730324 f1score:  0.8484465774185401 precision:  0.868912888831404 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.46314164415283676 f1score:  0.7726027397260274 precision:  0.7890775762253956 recall:  0.7568017767906718\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.462465365036407 f1score:  0.7520171457387796 precision:  0.7687350989110123 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.44976076555023925 f1score:  0.7857932123125494 precision:  0.8046683046683046 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.42748190279214066 f1score:  0.8697326473280516 precision:  0.8904472595656671 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4702820792906252 f1score:  0.7206974694699735 precision:  0.7356550793548802 recall:  0.706335986180517\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4586573354069466 f1score:  0.7643247684965709 precision:  0.7835666148263349 recall:  0.7460053056943673\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.46871008939974457 f1score:  0.767998455896545 precision:  0.8023795119983868 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.42921696468917436 f1score:  0.8691482649842271 precision:  0.8892905558065973 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.4361547603327611 f1score:  0.8570881837027586 precision:  0.8871649280338043 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.46589072098286455 f1score:  0.7439540316979226 precision:  0.7618493372130618 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.46004124774426397 f1score:  0.7520882584712372 precision:  0.7688837329208559 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4453226224410469 f1score:  0.8276820982777691 precision:  0.8484063228815756 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4823670852257547 f1score:  0.734549886148616 precision:  0.7648944696767299 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.44709765094156473 f1score:  0.8064556882066831 precision:  0.8261826182618262 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4724764728632203 f1score:  0.7285063609235118 precision:  0.7420965058236273 recall:  0.7154050219014128\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4677647664393257 f1score:  0.7426537746842619 precision:  0.758589628104491 recall:  0.7273736812881733\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4351243396469527 f1score:  0.8336318220378924 precision:  0.8494045332308875 recall:  0.8184342032204331\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.4511951549513562 f1score:  0.7938228805546802 precision:  0.8114167901552735 recall:  0.7769757542106237\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.4643592382913021 f1score:  0.7393806005345072 precision:  0.7539112592972557 recall:  0.7253994694305632\n",
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4617280747275558 f1score:  0.7769169960474309 precision:  0.7968993253762325 recall:  0.7579122709605774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.4951970851275257 f1score:  0.6691157679529771 precision:  0.6938058959920503 recall:  0.6461225245234129\n",
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.4640969446951141 f1score:  0.7334110897456104 precision:  0.7498388552275365 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4209104938271605 f1score:  0.8886999779603917 precision:  0.90747170781893 recall:  0.870689123326547\n"
     ]
    }
   ],
   "source": [
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_cond_acl_flow = {}\n",
    "gap_acl_flow = {}\n",
    "vol_acl_flow = {}\n",
    "size_clust_acl_flow = {}\n",
    "f1score_acl_flow = {}\n",
    "true_positives_acl_flow = {}\n",
    "precision_acl_flow = {}\n",
    "recall_acl_flow = {}\n",
    "cuts_acl_flow = {}\n",
    "\n",
    "cuts_best_pre_acl = np.load('results/cuts_best_pre_acl_sfld.npy')\n",
    "cuts_best_pre_acl = cuts_best_pre_acl[()]\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "\n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)    \n",
    "    \n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        ref_set = cuts_best_pre_acl[ct_outer,node]\n",
    "        \n",
    "        vol_ref_set = sum(g.d[ref_set])\n",
    "        dec = (1 - min(vol_ref_set/(vol_G - vol_ref_set),1))/3\n",
    "        delta = vol_ref_set/(vol_G - vol_ref_set) + dec\n",
    "        \n",
    "        output_mqi = lgc.flow_clustering(g,ref_set,method=\"sl\",delta=delta)\n",
    "        \n",
    "        S_flowI = output_mqi[0]\n",
    "        \n",
    "        cuts_acl_flow[ct_outer,node] = S_flowI\n",
    "\n",
    "        S_smqi, S_smqi_val = lgc.fiedler_local(g, S_flowI)\n",
    "        S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "        cond_val_acl_flow = output_mqi[1]\n",
    "\n",
    "        external_cond_acl_flow[ct_outer,node] = cond_val_acl_flow\n",
    "        gap_acl_flow[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_flowI])))/cond_val_acl_flow\n",
    "        vol_acl_flow[ct_outer,node] = sum(g.d[S_flowI])\n",
    "        size_clust_acl_flow[ct_outer,node] = len(S_flowI)\n",
    "            \n",
    "        true_positives_acl_flow[ct_outer,node] = set(rr).intersection(S_flowI)\n",
    "        if len(true_positives_acl_flow[ct_outer,node]) == 0:\n",
    "            true_positives_acl_flow[ct_outer,node] = set(ref_node)\n",
    "            vol_acl_flow[ct_outer,node] = g.d[ref_node][0]\n",
    "        precision_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/vol_acl_flow[ct_outer,node]\n",
    "        recall_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/sum(g.d[rr])\n",
    "        f1score_acl_flow[ct_outer,node] = 2*(precision_acl_flow[ct_outer,node]*recall_acl_flow[ct_outer,node])/(precision_acl_flow[ct_outer,node] + recall_acl_flow[ct_outer,node])\n",
    "            \n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', cond_val_acl_flow, 'f1score: ', f1score_acl_flow[ct_outer,node], 'precision: ', precision_acl_flow[ct_outer,node], 'recall: ', recall_acl_flow[ct_outer,node])\n",
    "        \n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "\n",
    "    np.save('results/size_clust_best_acl_flow_localflowImprove_parameter1_sfld', size_clust_acl_flow) \n",
    "    np.save('results/external_cond_best_acl_flow_localflowImprove_parameter1_sfld', external_cond_acl_flow)\n",
    "    np.save('results/vol_best_acl_flow_localflowImprove_parameter1_sfld', vol_acl_flow) \n",
    "    np.save('results/gap_best_acl_flow_localflowImprove_parameter1_sfld', gap_acl_flow) \n",
    "    np.save('results/cuts_best_acl_flow_localflowImprove_parameter1_sfld', cuts_acl_flow) \n",
    "    np.save('results/true_positives_best_acl_flow_localflowImprove_parameter1_sfld', true_positives_acl_flow)\n",
    "    np.save('results/recall_best_acl_flow_localflowImprove_parameter1_sfld', recall_acl_flow) \n",
    "    np.save('results/precision_best_acl_flow_localflowImprove_parameter1_sfld', precision_acl_flow) \n",
    "    np.save('results/f1score_best_acl_flow_localflowImprove_parameter1_sfld', f1score_acl_flow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the results found by the spectral algorithm using Local FlowImprove. Again, we use the SimpleLocal algorithm to solve the Local FlowImprove problem. This time we set a larger delta parameter. This will produce worse quality solutions, but the running time decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.438118493766868 f1score:  0.8243996097069655 precision:  0.8415370774964658 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4398547435315479 f1score:  0.718070260931201 precision:  0.5601479075232402 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.46773250146227335 f1score:  0.7566780605139891 precision:  0.7768895821147722 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4512658635573021 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.43108580302834215 f1score:  0.8808388339702493 precision:  0.9023553772486088 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.42756368386675375 f1score:  0.8956502427107458 precision:  0.9219464402351404 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.431287589730324 f1score:  0.8484465774185401 precision:  0.868912888831404 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.46314164415283676 f1score:  0.7726027397260274 precision:  0.7890775762253956 recall:  0.7568017767906718\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.462465365036407 f1score:  0.7520171457387796 precision:  0.7687350989110123 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.44976076555023925 f1score:  0.7857932123125494 precision:  0.8046683046683046 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.42748190279214066 f1score:  0.8697326473280516 precision:  0.8904472595656671 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4702820792906252 f1score:  0.7206974694699735 precision:  0.7356550793548802 recall:  0.706335986180517\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4586573354069466 f1score:  0.7643247684965709 precision:  0.7835666148263349 recall:  0.7460053056943673\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.46871008939974457 f1score:  0.767998455896545 precision:  0.8023795119983868 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.42921696468917436 f1score:  0.8691482649842271 precision:  0.8892905558065973 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.4361547603327611 f1score:  0.8570881837027586 precision:  0.8871649280338043 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.46589072098286455 f1score:  0.7439540316979226 precision:  0.7618493372130618 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.46004124774426397 f1score:  0.7520882584712372 precision:  0.7688837329208559 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4453226224410469 f1score:  0.8276820982777691 precision:  0.8484063228815756 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4823670852257547 f1score:  0.734549886148616 precision:  0.7648944696767299 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.44709765094156473 f1score:  0.8064556882066831 precision:  0.8261826182618262 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4724764728632203 f1score:  0.7285063609235118 precision:  0.7420965058236273 recall:  0.7154050219014128\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4677647664393257 f1score:  0.7426537746842619 precision:  0.758589628104491 recall:  0.7273736812881733\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4351243396469527 f1score:  0.8336318220378924 precision:  0.8494045332308875 recall:  0.8184342032204331\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.4511951549513562 f1score:  0.7938228805546802 precision:  0.8114167901552735 recall:  0.7769757542106237\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.4643592382913021 f1score:  0.7393806005345072 precision:  0.7539112592972557 recall:  0.7253994694305632\n",
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4617280747275558 f1score:  0.7769169960474309 precision:  0.7968993253762325 recall:  0.7579122709605774\n",
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.4951970851275257 f1score:  0.6691157679529771 precision:  0.6938058959920503 recall:  0.6461225245234129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.4640969446951141 f1score:  0.7334110897456104 precision:  0.7498388552275365 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4209104938271605 f1score:  0.8886999779603917 precision:  0.90747170781893 recall:  0.870689123326547\n"
     ]
    }
   ],
   "source": [
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_cond_acl_flow = {}\n",
    "gap_acl_flow = {}\n",
    "vol_acl_flow = {}\n",
    "size_clust_acl_flow = {}\n",
    "f1score_acl_flow = {}\n",
    "true_positives_acl_flow = {}\n",
    "precision_acl_flow = {}\n",
    "recall_acl_flow = {}\n",
    "cuts_acl_flow = {}\n",
    "\n",
    "cuts_best_pre_acl = np.load('results/cuts_best_pre_acl_sfld.npy')\n",
    "cuts_best_pre_acl = cuts_best_pre_acl[()]\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "    \n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)\n",
    "\n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        ref_set = cuts_best_pre_acl[ct_outer,node]\n",
    "\n",
    "        vol_ref_set = sum(g.d[ref_set])\n",
    "        dec = (1 - min(vol_ref_set/(vol_G - vol_ref_set),1))/3\n",
    "        delta = vol_ref_set/(vol_G - vol_ref_set) + 2*dec\n",
    "        \n",
    "        output_mqi = lgc.flow_clustering(g,ref_set,method=\"sl\",delta=delta)\n",
    "        \n",
    "        S_flowI = output_mqi[0]\n",
    "        \n",
    "        cuts_acl_flow[ct_outer,node] = S_flowI\n",
    "\n",
    "        S_smqi, S_smqi_val = lgc.fiedler_local(g, S_flowI)\n",
    "        S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "        cond_val_acl_flow = output_mqi[1]\n",
    "\n",
    "        external_cond_acl_flow[ct_outer,node] = cond_val_acl_flow\n",
    "        gap_acl_flow[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_flowI])))/cond_val_acl_flow\n",
    "        vol_acl_flow[ct_outer,node] = sum(g.d[S_flowI])\n",
    "        size_clust_acl_flow[ct_outer,node] = len(S_flowI)\n",
    "            \n",
    "        true_positives_acl_flow[ct_outer,node] = set(rr).intersection(S_flowI)\n",
    "        if len(true_positives_acl_flow[ct_outer,node]) == 0:\n",
    "            true_positives_acl_flow[ct_outer,node] = set(ref_node)\n",
    "            vol_acl_flow[ct_outer,node] = g.d[ref_node][0]\n",
    "        precision_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/vol_acl_flow[ct_outer,node]\n",
    "        recall_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/sum(g.d[rr])\n",
    "        f1score_acl_flow[ct_outer,node] = 2*(precision_acl_flow[ct_outer,node]*recall_acl_flow[ct_outer,node])/(precision_acl_flow[ct_outer,node] + recall_acl_flow[ct_outer,node])\n",
    "            \n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', cond_val_acl_flow, 'f1score: ', f1score_acl_flow[ct_outer,node], 'precision: ', precision_acl_flow[ct_outer,node], 'recall: ', recall_acl_flow[ct_outer,node])\n",
    "        \n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "\n",
    "    np.save('results/size_clust_best_acl_flow_localflowImprove_parameter2_sfld', size_clust_acl_flow) \n",
    "    np.save('results/external_cond_best_acl_flow_localflowImprove_parameter2_sfld', external_cond_acl_flow)\n",
    "    np.save('results/vol_best_acl_flow_localflowImprove_parameter2_sfld', vol_acl_flow) \n",
    "    np.save('results/gap_best_acl_flow_localflowImprove_parameter2_sfld', gap_acl_flow) \n",
    "    np.save('results/cuts_best_acl_flow_localflowImprove_parameter2_sfld', cuts_acl_flow) \n",
    "    np.save('results/true_positives_best_acl_flow_localflowImprove_parameter2_sfld', true_positives_acl_flow)\n",
    "    np.save('results/recall_best_acl_flow_localflowImprove_parameter2_sfld', recall_acl_flow) \n",
    "    np.save('results/precision_best_acl_flow_localflowImprove_parameter2_sfld', precision_acl_flow) \n",
    "    np.save('results/f1score_best_acl_flow_localflowImprove_parameter2_sfld', f1score_acl_flow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the results found by the spectral algorithm using Local FlowImprove. Again, we use the SimpleLocal algorithm to solve the Local FlowImprove problem. This time we set an even larger delta parameter. This will produce evem worse quality solutions, but the running time decreases even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "outer: 0 number of node:  51  completed:  0.0  degree:  157.0\n",
      "conductance:  0.438118493766868 f1score:  0.8243996097069655 precision:  0.8415370774964658 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  109  completed:  0.02  degree:  174.0\n",
      "conductance:  0.4398547435315479 f1score:  0.718070260931201 precision:  0.5601479075232402 recall:  1.0\n",
      "outer: 0 number of node:  130  completed:  0.04  degree:  170.0\n",
      "conductance:  0.46773250146227335 f1score:  0.7566780605139891 precision:  0.7768895821147722 recall:  0.7374915170584243\n",
      "outer: 0 number of node:  83  completed:  0.06  degree:  148.0\n",
      "conductance:  0.4265454779862051 f1score:  0.8759266239477322 precision:  0.892237793562424 recall:  0.860201122832994\n",
      "outer: 0 number of node:  117  completed:  0.08  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  55  completed:  0.1  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  45  completed:  0.12  degree:  159.0\n",
      "conductance:  0.4512658635573021 f1score:  0.7917426003896186 precision:  0.8067490555164244 recall:  0.7772842248133753\n",
      "outer: 0 number of node:  44  completed:  0.14  degree:  153.0\n",
      "conductance:  0.43108580302834215 f1score:  0.8808388339702493 precision:  0.9023553772486088 recall:  0.8603245110740947\n",
      "outer: 0 number of node:  43  completed:  0.16  degree:  151.0\n",
      "conductance:  0.42756368386675375 f1score:  0.8956502427107458 precision:  0.9219464402351404 recall:  0.8708125115676476\n",
      "outer: 0 number of node:  101  completed:  0.18  degree:  150.0\n",
      "conductance:  0.41879462275680196 f1score:  0.8983082824979561 precision:  0.9160520746488809 recall:  0.8812388179406503\n",
      "outer: 0 number of node:  98  completed:  0.2  degree:  159.0\n",
      "conductance:  0.431287589730324 f1score:  0.8484465774185401 precision:  0.868912888831404 recall:  0.8289222037139861\n",
      "outer: 0 number of node:  132  completed:  0.22  degree:  162.0\n",
      "conductance:  0.46314164415283676 f1score:  0.7726027397260274 precision:  0.7890775762253956 recall:  0.7568017767906718\n",
      "outer: 0 number of node:  93  completed:  0.24  degree:  161.0\n",
      "conductance:  0.462465365036407 f1score:  0.7520171457387796 precision:  0.7687350989110123 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  21  completed:  0.26  degree:  181.0\n",
      "conductance:  0.4950832315701523 f1score:  0.6804331402669352 precision:  0.6946461854874992 recall:  0.6667900549077673\n",
      "outer: 0 number of node:  17  completed:  0.28  degree:  164.0\n",
      "conductance:  0.44976076555023925 f1score:  0.7857932123125494 precision:  0.8046683046683046 recall:  0.7677833302486273\n",
      "outer: 0 number of node:  123  completed:  0.3  degree:  172.0\n",
      "conductance:  0.47702407002188185 f1score:  0.7410644116814938 precision:  0.7554800666581207 recall:  0.7271885989265223\n",
      "outer: 0 number of node:  87  completed:  0.32  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  99  completed:  0.34  degree:  157.0\n",
      "conductance:  0.42748190279214066 f1score:  0.8697326473280516 precision:  0.8904472595656671 recall:  0.8499598988216422\n",
      "outer: 0 number of node:  71  completed:  0.36  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  128  completed:  0.38  degree:  170.0\n",
      "conductance:  0.4702820792906252 f1score:  0.7206974694699735 precision:  0.7356550793548802 recall:  0.706335986180517\n",
      "outer: 0 number of node:  57  completed:  0.4  degree:  162.0\n",
      "conductance:  0.4586573354069466 f1score:  0.7643247684965709 precision:  0.7835666148263349 recall:  0.7460053056943673\n",
      "outer: 0 number of node:  115  completed:  0.42  degree:  171.0\n",
      "conductance:  0.46871008939974457 f1score:  0.767998455896545 precision:  0.8023795119983868 recall:  0.736442717009069\n",
      "outer: 0 number of node:  56  completed:  0.44  degree:  159.0\n",
      "conductance:  0.4305582383619857 f1score:  0.8584120982986768 precision:  0.8771489279505505 recall:  0.8404590042568943\n",
      "outer: 0 number of node:  114  completed:  0.46  degree:  163.0\n",
      "conductance:  0.4506080509852377 f1score:  0.7875007914899006 precision:  0.808805358652533 recall:  0.7672897772842248\n",
      "outer: 0 number of node:  95  completed:  0.48  degree:  148.0\n",
      "conductance:  0.427669308589471 f1score:  0.8654728243795161 precision:  0.8817617310031368 recall:  0.8497748164599913\n",
      "outer: 0 number of node:  63  completed:  0.5  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  40  completed:  0.52  degree:  153.0\n",
      "conductance:  0.42921696468917436 f1score:  0.8691482649842271 precision:  0.8892905558065973 recall:  0.849898204701092\n",
      "outer: 0 number of node:  52  completed:  0.54  degree:  159.0\n",
      "conductance:  0.4361547603327611 f1score:  0.8570881837027586 precision:  0.8871649280338043 recall:  0.8289838978345364\n",
      "outer: 0 number of node:  80  completed:  0.56  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  120  completed:  0.58  degree:  167.0\n",
      "conductance:  0.46589072098286455 f1score:  0.7439540316979226 precision:  0.7618493372130618 recall:  0.7268801283237707\n",
      "outer: 0 number of node:  74  completed:  0.6  degree:  163.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  48  completed:  0.62  degree:  159.0\n",
      "conductance:  0.4443511401072282 f1score:  0.7903225806451613 precision:  0.8042020563254358 recall:  0.7769140600900735\n",
      "outer: 0 number of node:  88  completed:  0.64  degree:  161.0\n",
      "conductance:  0.46004124774426397 f1score:  0.7520882584712372 precision:  0.7688837329208559 recall:  0.7360108581652168\n",
      "outer: 0 number of node:  104  completed:  0.66  degree:  154.0\n",
      "conductance:  0.4453226224410469 f1score:  0.8276820982777691 precision:  0.8484063228815756 recall:  0.8079462027268801\n",
      "outer: 0 number of node:  67  completed:  0.68  degree:  166.0\n",
      "conductance:  0.45635330578512395 f1score:  0.7918144439910864 precision:  0.8059033989266547 recall:  0.77820963662163\n",
      "outer: 0 number of node:  53  completed:  0.7  degree:  179.0\n",
      "conductance:  0.4823670852257547 f1score:  0.734549886148616 precision:  0.7648944696767299 recall:  0.7065210685421679\n",
      "outer: 0 number of node:  62  completed:  0.72  degree:  160.0\n",
      "conductance:  0.44709765094156473 f1score:  0.8064556882066831 precision:  0.8261826182618262 recall:  0.7876488370658277\n",
      "outer: 0 number of node:  76  completed:  0.74  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  50  completed:  0.76  degree:  171.0\n",
      "conductance:  0.4724764728632203 f1score:  0.7285063609235118 precision:  0.7420965058236273 recall:  0.7154050219014128\n",
      "outer: 0 number of node:  131  completed:  0.78  degree:  168.0\n",
      "conductance:  0.4677647664393257 f1score:  0.7426537746842619 precision:  0.758589628104491 recall:  0.7273736812881733\n",
      "outer: 0 number of node:  65  completed:  0.8  degree:  165.0\n",
      "conductance:  0.4520778129645188 f1score:  0.7952780758790482 precision:  0.8141924642926388 recall:  0.777222530692825\n",
      "outer: 0 number of node:  54  completed:  0.82  degree:  154.0\n",
      "conductance:  0.4351243396469527 f1score:  0.8336318220378924 precision:  0.8494045332308875 recall:  0.8184342032204331\n",
      "outer: 0 number of node:  84  completed:  0.84  degree:  157.0\n",
      "conductance:  0.429441492808086 f1score:  0.8599058243529375 precision:  0.8814953997667487 recall:  0.8393485100869887\n",
      "outer: 0 number of node:  97  completed:  0.86  degree:  163.0\n",
      "conductance:  0.4511951549513562 f1score:  0.7938228805546802 precision:  0.8114167901552735 recall:  0.7769757542106237\n",
      "outer: 0 number of node:  31  completed:  0.88  degree:  166.0\n",
      "conductance:  0.4643592382913021 f1score:  0.7393806005345072 precision:  0.7539112592972557 recall:  0.7253994694305632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer: 0 number of node:  94  completed:  0.9  degree:  167.0\n",
      "conductance:  0.4617280747275558 f1score:  0.7769169960474309 precision:  0.7968993253762325 recall:  0.7579122709605774\n",
      "outer: 0 number of node:  20  completed:  0.92  degree:  181.0\n",
      "conductance:  0.4951970851275257 f1score:  0.6691157679529771 precision:  0.6938058959920503 recall:  0.6461225245234129\n",
      "outer: 0 number of node:  124  completed:  0.94  degree:  172.0\n",
      "conductance:  0.4640969446951141 f1score:  0.7334110897456104 precision:  0.7498388552275365 recall:  0.7176877043617743\n",
      "outer: 0 number of node:  61  completed:  0.96  degree:  155.0\n",
      "conductance:  0.4358675976208948 f1score:  0.8532982026912581 precision:  0.8679173047473201 recall:  0.8391634277253378\n",
      "outer: 0 number of node:  69  completed:  0.98  degree:  152.0\n",
      "conductance:  0.4209104938271605 f1score:  0.8886999779603917 precision:  0.90747170781893 recall:  0.870689123326547\n"
     ]
    }
   ],
   "source": [
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_cond_acl_flow = {}\n",
    "gap_acl_flow = {}\n",
    "vol_acl_flow = {}\n",
    "size_clust_acl_flow = {}\n",
    "f1score_acl_flow = {}\n",
    "true_positives_acl_flow = {}\n",
    "precision_acl_flow = {}\n",
    "recall_acl_flow = {}\n",
    "cuts_acl_flow = {}\n",
    "\n",
    "cuts_best_pre_acl = np.load('results/cuts_best_pre_acl_sfld.npy')\n",
    "cuts_best_pre_acl = cuts_best_pre_acl[()]\n",
    "\n",
    "ct_outer = 0\n",
    "for rr in ref_nodes:\n",
    "    \n",
    "    how_many = int(len(rr)/2)\n",
    "    print(how_many)\n",
    "\n",
    "    ct = 0\n",
    "    for node in nodes[ct_outer]:\n",
    "        ref_node = [node]\n",
    "\n",
    "        ref_set = cuts_best_pre_acl[ct_outer,node]\n",
    "\n",
    "        vol_ref_set = sum(g.d[ref_set])\n",
    "        dec = (1 - min(vol_ref_set/(vol_G - vol_ref_set),1))/3\n",
    "        delta = vol_ref_set/(vol_G - vol_ref_set) + 3*dec\n",
    "        \n",
    "        output_mqi = lgc.flow_clustering(g,ref_set,method=\"sl\",delta=delta)\n",
    "        \n",
    "        S_flowI = output_mqi[0]\n",
    "        \n",
    "        cuts_acl_flow[ct_outer,node] = S_flowI\n",
    "\n",
    "        S_smqi, S_smqi_val = lgc.fiedler_local(g, S_flowI)\n",
    "        S_smqi_val = np.real(S_smqi_val)\n",
    "\n",
    "        cond_val_acl_flow = output_mqi[1]\n",
    "\n",
    "        external_cond_acl_flow[ct_outer,node] = cond_val_acl_flow\n",
    "        gap_acl_flow[ct_outer,node] = (S_smqi_val/np.log(sum(g.d[S_flowI])))/cond_val_acl_flow\n",
    "        vol_acl_flow[ct_outer,node] = sum(g.d[S_flowI])\n",
    "        size_clust_acl_flow[ct_outer,node] = len(S_flowI)\n",
    "            \n",
    "        true_positives_acl_flow[ct_outer,node] = set(rr).intersection(S_flowI)\n",
    "        if len(true_positives_acl_flow[ct_outer,node]) == 0:\n",
    "            true_positives_acl_flow[ct_outer,node] = set(ref_node)\n",
    "            vol_acl_flow[ct_outer,node] = g.d[ref_node][0]\n",
    "        precision_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/vol_acl_flow[ct_outer,node]\n",
    "        recall_acl_flow[ct_outer,node] = sum(g.d[np.array(list(true_positives_acl_flow[ct_outer,node]))])/sum(g.d[rr])\n",
    "        f1score_acl_flow[ct_outer,node] = 2*(precision_acl_flow[ct_outer,node]*recall_acl_flow[ct_outer,node])/(precision_acl_flow[ct_outer,node] + recall_acl_flow[ct_outer,node])\n",
    "            \n",
    "\n",
    "        print('outer:', ct_outer, 'number of node: ',node, ' completed: ', ct/how_many, ' degree: ', g.d[node])\n",
    "        print('conductance: ', cond_val_acl_flow, 'f1score: ', f1score_acl_flow[ct_outer,node], 'precision: ', precision_acl_flow[ct_outer,node], 'recall: ', recall_acl_flow[ct_outer,node])\n",
    "        \n",
    "        ct += 1\n",
    "    ct_outer += 1\n",
    "\n",
    "    np.save('results/size_clust_best_acl_flow_localflowImprove_parameter3_sfld', size_clust_acl_flow) \n",
    "    np.save('results/external_cond_best_acl_flow_localflowImprove_parameter3_sfld', external_cond_acl_flow)\n",
    "    np.save('results/vol_best_acl_flow_localflowImprove_parameter3_sfld', vol_acl_flow) \n",
    "    np.save('results/gap_best_acl_flow_localflowImprove_parameter3_sfld', gap_acl_flow) \n",
    "    np.save('results/cuts_best_acl_flow_localflowImprove_parameter3_sfld', cuts_acl_flow) \n",
    "    np.save('results/true_positives_best_acl_flow_localflowImprove_parameter3_sfld', true_positives_acl_flow)\n",
    "    np.save('results/recall_best_acl_flow_localflowImprove_parameter3_sfld', recall_acl_flow) \n",
    "    np.save('results/precision_best_acl_flow_localflowImprove_parameter3_sfld', precision_acl_flow) \n",
    "    np.save('results/f1score_best_acl_flow_localflowImprove_parameter3_sfld', f1score_acl_flow) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_info_ref_nodes = len(info_ref_nodes)\n",
    "\n",
    "nodes = np.load('results/nodes_sfld.npy')\n",
    "nodes = nodes[()]\n",
    "\n",
    "external_best_cond_acl = np.load('results/external_best_cond_acl_sfld.npy')\n",
    "external_best_cond_acl = external_best_cond_acl[()]\n",
    "external_cond_best_acl_flow_mqi = np.load('results/external_cond_best_acl_flow_mqi_sfld.npy')\n",
    "external_cond_best_acl_flow_mqi = external_cond_best_acl_flow_mqi[()]\n",
    "external_cond_best_acl_flow_flowImprove = np.load('results/external_cond_best_acl_flow_flowImprove_sfld.npy')\n",
    "external_cond_best_acl_flow_flowImprove = external_cond_best_acl_flow_flowImprove[()]\n",
    "external_cond_best_acl_flow_localflowImprove_parameter1 = np.load('results/external_cond_best_acl_flow_localflowImprove_parameter1_sfld.npy')\n",
    "external_cond_best_acl_flow_localflowImprove_parameter1 = external_cond_best_acl_flow_localflowImprove_parameter1[()]\n",
    "external_cond_best_acl_flow_localflowImprove_parameter2 = np.load('results/external_cond_best_acl_flow_localflowImprove_parameter2_sfld.npy')\n",
    "external_cond_best_acl_flow_localflowImprove_parameter2 = external_cond_best_acl_flow_localflowImprove_parameter2[()]\n",
    "external_cond_best_acl_flow_localflowImprove_parameter3 = np.load('results/external_cond_best_acl_flow_localflowImprove_parameter3_sfld.npy')\n",
    "external_cond_best_acl_flow_localflowImprove_parameter3 = external_cond_best_acl_flow_localflowImprove_parameter3[()]\n",
    "\n",
    "precision_mqi = np.load('results/precision_best_acl_flow_mqi_sfld.npy')\n",
    "precision_mqi = precision_mqi[()]\n",
    "recall_mqi = np.load('results/recall_best_acl_flow_mqi_sfld.npy')\n",
    "recall_mqi = recall_mqi[()]\n",
    "f1_mqi = np.load('results/f1score_best_acl_flow_mqi_sfld.npy')\n",
    "f1_mqi = f1_mqi[()]\n",
    "precision_best_pre_acl = np.load('results/precision_best_pre_acl_sfld.npy')\n",
    "precision_best_pre_acl = precision_best_pre_acl[()]\n",
    "recall_best_pre_acl = np.load('results/recall_best_pre_acl_sfld.npy')\n",
    "recall_best_pre_acl = recall_best_pre_acl[()]\n",
    "f1score_best_pre_acl = np.load('results/f1score_best_pre_acl_sfld.npy')\n",
    "f1score_best_pre_acl = f1score_best_pre_acl[()]\n",
    "precision_acl_flow_localflowImprove = np.load('results/precision_best_acl_flow_flowImprove_sfld.npy')\n",
    "precision_acl_flow_localflowImprove = precision_acl_flow_localflowImprove[()]\n",
    "recall_acl_flow_localflowImprove = np.load('results/recall_best_acl_flow_flowImprove_sfld.npy')\n",
    "recall_acl_flow_localflowImprove = recall_acl_flow_localflowImprove[()]\n",
    "f1score_acl_flow_flowImprove = np.load('results/f1score_best_acl_flow_flowImprove_sfld.npy')\n",
    "f1score_acl_flow_flowImprove = f1score_acl_flow_flowImprove[()]\n",
    "precision_acl_flow_localflowImprove_parameter1 = np.load('results/precision_best_acl_flow_localflowImprove_parameter1_sfld.npy')\n",
    "precision_acl_flow_localflowImprove_parameter1 = precision_acl_flow_localflowImprove_parameter1[()]\n",
    "recall_acl_flow_localflowImprove_parameter1 = np.load('results/recall_best_acl_flow_localflowImprove_parameter1_sfld.npy')\n",
    "recall_acl_flow_localflowImprove_parameter1 = recall_acl_flow_localflowImprove_parameter1[()]\n",
    "f1_acl_flow_localflowImprove_parameter1 = np.load('results/f1score_best_acl_flow_localflowImprove_parameter1_sfld.npy')\n",
    "f1_acl_flow_localflowImprove_parameter1 = f1_acl_flow_localflowImprove_parameter1[()]\n",
    "precision_acl_flow_localflowImprove_parameter2 = np.load('results/precision_best_acl_flow_localflowImprove_parameter2_sfld.npy')\n",
    "precision_acl_flow_localflowImprove_parameter2 = precision_acl_flow_localflowImprove_parameter2[()]\n",
    "recall_acl_flow_localflowImprove_parameter2 = np.load('results/recall_best_acl_flow_localflowImprove_parameter2_sfld.npy')\n",
    "recall_acl_flow_localflowImprove_parameter2 = recall_acl_flow_localflowImprove_parameter2[()]\n",
    "f1_acl_flow_localflowImprove_parameter2 = np.load('results/f1score_best_acl_flow_localflowImprove_parameter2_sfld.npy')\n",
    "f1_acl_flow_localflowImprove_parameter2 = f1_acl_flow_localflowImprove_parameter2[()]\n",
    "precision_acl_flow_localflowImprove_parameter3 = np.load('results/precision_best_acl_flow_localflowImprove_parameter3_sfld.npy')\n",
    "precision_acl_flow_localflowImprove_parameter3 = precision_acl_flow_localflowImprove_parameter3[()]\n",
    "recall_acl_flow_localflowImprove_parameter3 = np.load('results/recall_best_acl_flow_localflowImprove_parameter3_sfld.npy')\n",
    "recall_acl_flow_localflowImprove_parameter3 = recall_acl_flow_localflowImprove_parameter3[()]\n",
    "f1_acl_flow_localflowImprove_parameter3 = np.load('results/f1score_best_acl_flow_localflowImprove_parameter3_sfld.npy')\n",
    "f1_acl_flow_localflowImprove_parameter3 = f1_acl_flow_localflowImprove_parameter3[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scatter plot for F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = []\n",
    "xlabels_ = []\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1score_best_pre_acl[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1_mqi[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1score_acl_flow_flowImprove[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter1[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter2[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_f1  = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter3[i,j])\n",
    "    all_data.append(temp_f1)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "axes = plt.gca()\n",
    "\n",
    "# notch shape box plot\n",
    "bplot2 = axes.boxplot(all_data,\n",
    "                         notch=False,  # notch shape\n",
    "                         vert=True,   # vertical box aligmnent\n",
    "                         patch_artist=True,   # fill with color\n",
    "                         showfliers=False,widths=0.8)\n",
    "\n",
    "# adding horizontal grid lines\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xticks([y+1 for y in range(len(all_data))])\n",
    "axes.set_ylabel('F1 score',fontsize=30)\n",
    "#axes.set_xlabel('Year')\n",
    "\n",
    "# add x-tick labels\n",
    "#plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "#         xticklabels=[info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1]], info_ref_nodes[0][1], info_ref_nodes[0][1])\n",
    "\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],xticklabels=xlabels_)\n",
    "axes.set_xticklabels(axes.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "axes.tick_params(labelsize=20)\n",
    "\n",
    "plt.text(2, 1.07, 'ACLopt', fontsize=25)\n",
    "plt.text(7.4, 1.07, 'MQI', fontsize=25)\n",
    "plt.text(12.0, 1.07, 'FlowI', fontsize=25)\n",
    "plt.text(16.8, 1.07, 'FlowI-1', fontsize=25)\n",
    "plt.text(21.8, 1.07, 'FlowI-2', fontsize=25)\n",
    "plt.text(26.7, 1.07, 'FlowI-3', fontsize=25)\n",
    "\n",
    "\n",
    "#plt.text(0.75, 0.18, 'Prec.', fontsize=10, rotation=90)\n",
    "#plt.text(1.8, 0.18, 'Rec.', fontsize=10, rotation=90)\n",
    "\n",
    "plt.plot([5.5, 5.5], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([10.45, 10.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([15.45, 15.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([20.45, 20.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([25.5, 25.5], [0, 1], 'k:', linewidth=1)\n",
    "\n",
    "plt.savefig('figures/boxplot_sfld_Optimal.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scatter plot for precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = []\n",
    "xlabels_ = []\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_best_pre_acl[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_mqi[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1])) \n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter1[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter2[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter3[i,j])\n",
    "    all_data.append(temp_pre)\n",
    "    \n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "axes = plt.gca()\n",
    "\n",
    "# notch shape box plot\n",
    "bplot2 = axes.boxplot(all_data,\n",
    "                         notch=False,  # notch shape\n",
    "                         vert=True,   # vertical box aligmnent\n",
    "                         patch_artist=True,   # fill with color\n",
    "                         showfliers=False,widths=0.8)\n",
    "\n",
    "# adding horizontal grid lines\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xticks([y+1 for y in range(len(all_data))])\n",
    "axes.set_ylabel('Precision',fontsize=30)\n",
    "#axes.set_xlabel('Year')\n",
    "\n",
    "# add x-tick labels\n",
    "#plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "#         xticklabels=[info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1]], info_ref_nodes[0][1], info_ref_nodes[0][1])\n",
    "\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],xticklabels=xlabels_)\n",
    "axes.set_xticklabels(axes.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "axes.tick_params(labelsize=20)\n",
    "\n",
    "plt.text(2, 1.07, 'ACLopt', fontsize=25)\n",
    "plt.text(7.4, 1.07, 'MQI', fontsize=25)\n",
    "plt.text(12.0, 1.07, 'FlowI', fontsize=25)\n",
    "plt.text(16.8, 1.07, 'FlowI-1', fontsize=25)\n",
    "plt.text(21.8, 1.07, 'FlowI-2', fontsize=25)\n",
    "plt.text(26.7, 1.07, 'FlowI-3', fontsize=25)\n",
    "\n",
    "\n",
    "#plt.text(0.75, 0.18, 'Prec.', fontsize=10, rotation=90)\n",
    "#plt.text(1.8, 0.18, 'Rec.', fontsize=10, rotation=90)\n",
    "\n",
    "plt.plot([5.5, 5.5], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([10.45, 10.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([15.45, 15.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([20.45, 20.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([25.5, 25.5], [0, 1], 'k:', linewidth=1)\n",
    "\n",
    "plt.savefig('figures/boxplot_sfld_Optimal.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate scatter plot for recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_data = []\n",
    "xlabels_ = []\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_best_pre_acl[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_mqi[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter1[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter2[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "    \n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_rec = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter3[i,j])\n",
    "    all_data.append(temp_rec)\n",
    "\n",
    "    xlabels_.append(int(info_ref_nodes[i,1]))\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "axes = plt.gca()\n",
    "\n",
    "# notch shape box plot\n",
    "bplot2 = axes.boxplot(all_data,\n",
    "                         notch=False,  # notch shape\n",
    "                         vert=True,   # vertical box aligmnent\n",
    "                         patch_artist=True,   # fill with color\n",
    "                         showfliers=False,widths=0.8)\n",
    "\n",
    "# adding horizontal grid lines\n",
    "axes.yaxis.grid(True)\n",
    "axes.set_xticks([y+1 for y in range(len(all_data))])\n",
    "axes.set_ylabel('Recall',fontsize=30)\n",
    "#axes.set_xlabel('Year')\n",
    "\n",
    "# add x-tick labels\n",
    "#plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "#         xticklabels=[info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1], info_ref_nodes[0][1]], info_ref_nodes[0][1], info_ref_nodes[0][1])\n",
    "\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],xticklabels=xlabels_)\n",
    "axes.set_xticklabels(axes.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "axes.tick_params(labelsize=20)\n",
    "\n",
    "plt.text(2, 1.07, 'ACLopt', fontsize=25)\n",
    "plt.text(7.4, 1.07, 'MQI', fontsize=25)\n",
    "plt.text(12.0, 1.07, 'FlowI', fontsize=25)\n",
    "plt.text(16.8, 1.07, 'FlowI-1', fontsize=25)\n",
    "plt.text(21.8, 1.07, 'FlowI-2', fontsize=25)\n",
    "plt.text(26.7, 1.07, 'FlowI-3', fontsize=25)\n",
    "\n",
    "\n",
    "#plt.text(0.75, 0.18, 'Prec.', fontsize=10, rotation=90)\n",
    "#plt.text(1.8, 0.18, 'Rec.', fontsize=10, rotation=90)\n",
    "\n",
    "plt.plot([5.5, 5.5], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([10.45, 10.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([15.45, 15.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([20.45, 20.45], [0, 1], 'k:', linewidth=1)\n",
    "plt.plot([25.5, 25.5], [0, 1], 'k:', linewidth=1)\n",
    "\n",
    "plt.savefig('figures/boxplot_sfld_Optimal.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate precision/recall and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ACLopt\n",
      "Feature: 22.0 Precision 0.8059033989266547 Recall 0.7772533777531001 F1 0.7918144439910864 Cond. 0.4392165478562424\n",
      "Average precision 0.8059033989266547 Average recall 0.7772533777531001 Average F1 0.7918144439910864 Av. Cond. 0.4392165478562424\n",
      " \n",
      "Results for MQIopt\n",
      "Feature: 22.0 Precision 0.8063262272215396 Recall 0.7772533777531001 F1 0.7918144439910864 Cond. 0.45090160296829696\n",
      "Average precision 0.8063262272215396 Average recall 0.7772533777531001 Average F1 0.7918144439910864 Av. Cond. 0.45090160296829696\n",
      " \n",
      "Results for FlowIopt\n",
      "Feature: 22.0 Precision 0.7868944537455024 Recall 0.8451169103584428 F1 0.7623382582052671 Cond. 0.43601117897682795\n",
      "Average precision 0.7868944537455024 Average recall 0.8451169103584428 Average F1 0.7623382582052671 Av. Cond. 0.43601117897682795\n",
      " \n",
      "Results for FlowI-1opt\n",
      "Feature: 22.0 Precision 0.8063262272215396 Recall 0.7772533777531001 F1 0.7918144439910864 Cond. 0.45090160296829696\n",
      "Average precision 0.8063262272215396 Average recall 0.7772533777531001 Average F1 0.7918144439910864 Av. Cond. 0.45090160296829696\n",
      " \n",
      "Results for FlowI-2opt\n",
      "Feature: 22.0 Precision 0.8063262272215396 Recall 0.7772533777531001 F1 0.7918144439910864 Cond. 0.45090160296829696\n",
      "Average precision 0.8063262272215396 Average recall 0.7772533777531001 Average F1 0.7918144439910864 Av. Cond. 0.45090160296829696\n",
      " \n",
      "Results for FlowI-3opt\n",
      "Feature: 22.0 Precision 0.8063262272215396 Recall 0.7772533777531001 F1 0.7918144439910864 Cond. 0.45090160296829696\n",
      "Average precision 0.8063262272215396 Average recall 0.7772533777531001 Average F1 0.7918144439910864 Av. Cond. 0.45090160296829696\n",
      " \n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "xlabels_ = []\n",
    "\n",
    "print('Results for ACLopt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_best_pre_acl[i,j])\n",
    "        temp_rec.append(recall_best_pre_acl[i,j])\n",
    "        temp_f1.append(f1score_best_pre_acl[i,j])\n",
    "        temp_conductance.append(external_best_cond_acl[i,j])\n",
    "\n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")\n",
    "    \n",
    "print('Results for MQIopt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_mqi[i,j])\n",
    "        temp_rec.append(recall_mqi[i,j])\n",
    "        temp_f1.append(f1_mqi[i,j])\n",
    "        temp_conductance.append(external_cond_best_acl_flow_mqi[i,j])\n",
    "        \n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")\n",
    "\n",
    "print('Results for FlowIopt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove[i,j])\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove[i,j])\n",
    "        temp_f1.append(f1score_acl_flow_flowImprove[i,j])\n",
    "        temp_conductance.append(external_cond_best_acl_flow_flowImprove[i,j])\n",
    "        \n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")\n",
    "\n",
    "print('Results for FlowI-1opt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter1[i,j])\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter1[i,j])\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter1[i,j])\n",
    "        temp_conductance.append(external_cond_best_acl_flow_localflowImprove_parameter1[i,j])\n",
    "\n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")\n",
    "\n",
    "print('Results for FlowI-2opt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter2[i,j])\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter2[i,j])\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter2[i,j])\n",
    "        temp_conductance.append(external_cond_best_acl_flow_localflowImprove_parameter2[i,j])\n",
    "        \n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")\n",
    "\n",
    "print('Results for FlowI-3opt')\n",
    "sum_precision = 0\n",
    "sum_recall = 0\n",
    "sum_f1 = 0\n",
    "sum_conductance = 0\n",
    "for i in range(l_info_ref_nodes):\n",
    "    temp_pre = []\n",
    "    temp_rec = []\n",
    "    temp_f1 = []\n",
    "    temp_conductance = []\n",
    "    \n",
    "    for j in nodes[i]:\n",
    "        temp_pre.append(precision_acl_flow_localflowImprove_parameter3[i,j])\n",
    "        temp_rec.append(recall_acl_flow_localflowImprove_parameter3[i,j])\n",
    "        temp_f1.append(f1_acl_flow_localflowImprove_parameter3[i,j])\n",
    "        temp_conductance.append(external_cond_best_acl_flow_localflowImprove_parameter3[i,j])\n",
    "        \n",
    "    print('Feature:', info_ref_nodes[i,1],'Precision', stat_.median(temp_pre), 'Recall', stat_.median(temp_rec), 'F1', stat_.median(temp_f1), 'Cond.', stat_.median(temp_conductance))    \n",
    "    sum_precision += stat_.median(temp_pre)\n",
    "    sum_recall += stat_.median(temp_rec)\n",
    "    sum_f1 += stat_.median(temp_f1)\n",
    "    sum_conductance += stat_.median(temp_conductance)\n",
    "    \n",
    "avg_precision = sum_precision/l_info_ref_nodes\n",
    "avg_recall = sum_recall/l_info_ref_nodes\n",
    "avg_f1 = sum_f1/l_info_ref_nodes\n",
    "avg_conductance = sum_conductance/l_info_ref_nodes\n",
    "    \n",
    "print('Average precision', avg_precision, 'Average recall', avg_recall, 'Average F1', avg_f1, 'Av. Cond.', avg_conductance)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
